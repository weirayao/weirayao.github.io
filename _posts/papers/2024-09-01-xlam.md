---
layout: paper
categories: papers
permalink: papers/xlam
id: xlam
title: "xLAM: A Family of Large Action Models to Empower AI Agent Systems"
authors:
  - Jianguo Zhang
  - Tian Lan
  - Ming Zhu
  - Zuxin Liu
  - Thai Hoang
  - Shirley Kokane
  - Weiran Yao
  - Juntao Tan
  - Akshara Prabhakar
  - Haolin Chen
  - Zhiwei Liu
  - Yihao Feng
  - Tulika Awalgaonkar
  - Rithesh Murthy
  - Eric Hu
  - Zeyuan Chen
  - Ran Xu
  - Juan Carlos Niebles
  - Shelby Heinecke
  - Huan Wang
  - Silvio Savarese
  - Caiming Xiong
equal-contribution:
  - Jianguo Zhang
  - Tian Lan
  - Ming Zhu
  - Zuxin Liu
  - Thai Hoang
  - Shirley Kokane
  - Weiran Yao
venue: arXiv:2409.03215
venue-shorthand: arXiv
year: 2024
url: /papers/xlam
pdf: https://arxiv.org/pdf/2409.03215
award: Deployed at Salesforce
code: https://github.com/SalesforceAIResearch/xLAM
demo: https://www.salesforce.com/plus/experience/dreamforce_2024/series/the_future_of_ai_at_dreamforce_2024/episode/episode-s1e21?t=1667 
blog: https://blog.salesforceairesearch.com/large-action-model-ai-agent/
preview: https://gorilla.cs.berkeley.edu/leaderboard.html
slides: https://docs.google.com/presentation/d/179AhjWD9V7AUs3ARCcZcVqtY4j82sQuy_-eiSPDF4sk/edit?usp=sharing
feature-title: Large Action Model
feature-description: World's Best Open-Source Model for Function-Calling
image: /images/featured/xlam.png
feature-order: 2
featured: true
selected: true
type: conference
figure: /images/papers/24-xlam-arxiv.png
bibtex: |-

  @misc{zhang2024xlamfamilylargeaction,
    title={xLAM: A Family of Large Action Models to Empower AI Agent Systems}, 
    author={Jianguo Zhang and Tian Lan and Ming Zhu and Zuxin Liu and Thai Hoang and Shirley Kokane and Weiran Yao and Juntao Tan and Akshara Prabhakar and Haolin Chen and Zhiwei Liu and Yihao Feng and Tulika Awalgaonkar and Rithesh Murthy and Eric Hu and Zeyuan Chen and Ran Xu and Juan Carlos Niebles and Shelby Heinecke and Huan Wang and Silvio Savarese and Caiming Xiong},
    year={2024},
    eprint={2409.03215},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2409.03215}, 
  }

---

Autonomous agents powered by large language models (LLMs) have attracted significant research interest. However, the open-source community faces many challenges in developing specialized models for agent tasks, driven by the scarcity of high-quality agent datasets and the absence of standard protocols in this area. We introduce and publicly release xLAM, a series of large action models designed for AI agent tasks. The xLAM series includes five models with both dense and mixture-of-expert architectures, ranging from 1B to 8x22B parameters, trained using a scalable, flexible pipeline that unifies, augments, and synthesizes diverse datasets to enhance AI agents' generalizability and performance across varied environments. Our experimental results demonstrate that xLAM consistently delivers exceptional performance across multiple agent ability benchmarks, notably securing the 1st position on the Berkeley Function-Calling Leaderboard, outperforming GPT-4, Claude-3, and many other models in terms of tool use. By releasing the xLAM series, we aim to advance the performance of open-source LLMs for autonomous AI agents, potentially accelerating progress and democratizing access to high-performance models for agent tasks. Models are available at: [this URL](https://huggingface.co/collections/Salesforce/xlam-models-65f00e2a0a63bbcd1c2dade4)
