---
layout: paper
categories: papers
permalink: papers/drdt
id: drdt
title: "DRDT: Dynamic Reflection with Divergent Thinking for LLM-based Sequential Recommendation"
authors: 
  - Yu Wang
  - Zhiwei Liu
  - Jianguo Zhang
  - Weiran Yao
  - Shelby Heinecke
  - Philip S. Yu
venue: arXiv:2312.11336
venue-shorthand: arXiv
year: 2023
url: /papers/drdt
pdf: https://arxiv.org/pdf/2312.11336
featured: false
feature-title: DRDT
feature-description: Personalized Recommender Systems Using LLM
selected: false
type: conference
bibtex: |-
  
    @article{wang2023drdt,
      title={Drdt: Dynamic reflection with divergent thinking for llm-based sequential recommendation},
      author={Wang, Yu and Liu, Zhiwei and Zhang, Jianguo and Yao, Weiran and Heinecke, Shelby and Yu, Philip S},
      journal={arXiv preprint arXiv:2312.11336},
      year={2023}
    }
---

The rise of Large Language Models (LLMs) has sparked interest in their application to sequential recommendation tasks as they can provide supportive item information. However, due to the inherent complexities of sequential recommendation, such as sequential patterns across datasets, noise within sequences, and the temporal evolution of user preferences, existing LLM reasoning strategies, such as in-context learning and chain-of-thought are not fully effective. To address these challenges, we introduce a novel reasoning principle: Dynamic Reflection with Divergent Thinking within a retriever-reranker framework. Our approach starts with a collaborative in-context demonstration retriever, which collects sequences exhibiting collaborative behaviors as in-context examples. Following this, we abstract high-level user preferences across multiple aspects, providing a more nuanced understanding of user interests and circumventing the noise within the raw sequences. The cornerstone of our methodology is dynamic reflection, a process that emulates human learning through probing, critiquing, and reflecting, using user feedback to tailor the analysis more effectively to the target user in a temporal manner. We evaluate our approach on three datasets using six pre-trained LLMs. The superior performance observed across these models demonstrates the efficacy of our reasoning strategy, notably achieved without the need to fine-tune the LLMs. With our principle, we managed to outperform GPT-Turbo-3.5 on three datasets using 7b models e.g., Vicuna-7b and Openchat-7b on NDCG@10. This research not only highlights the potential of LLMs in enhancing sequential recommendation systems but also underscores the importance of developing tailored reasoning strategies to fully harness their capabilities.

