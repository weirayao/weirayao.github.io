---
layout: paper
categories: papers
permalink: papers/bolaa
id: bolaa
title: "BOLAA: Benchmarking and Orchestrating LLM-augmented Autonomous Agents"
authors:
  - Zhiwei Liu
  - Weiran Yao
  - Jianguo Zhang
  - Le Xue
  - Shelby Heinecke
  - Rithesh Murthy
  - Yihao Feng
  - Zeyuan Chen
  - Juan Carlos Niebles
  - Devansh Arpit
  - Ran Xu
  - Phil Mui
  - Huan Wang
  - Caiming Xiong
  - Silvio Savarese
venue: International Conference on Learning Representations
venue-shorthand: ICLR
year: 2024
url: /papers/agentlite
pdf: https://arxiv.org/pdf/2308.05960
code: https://github.com/salesforce/BOLAA
preview: https://github.com/salesforce/BOLAA/blob/main/page/BOLAA-webshop.gif
feature-title: BOLAA
feature-description: Unified Benchmarks for Orchestrating Language Agents
image: /images/featured/agentlite.png
feature-order: 1
featured: false
selected: true
type: conference
figure: /images/papers/23-bolaa-iclr.png
bibtex: |-

    @article{liu2023bolaa,
      title={Bolaa: Benchmarking and orchestrating llm-augmented autonomous agents},
      author={Liu, Zhiwei and Yao, Weiran and Zhang, Jianguo and Xue, Le and Heinecke, Shelby and Murthy, Rithesh and Feng, Yihao and Chen, Zeyuan and Niebles, Juan Carlos and Arpit, Devansh and others},
      journal={arXiv preprint arXiv:2308.05960},
      year={2023}
    }

---

The massive successes of large language models (LLMs) encourage the emerging exploration of LLM-augmented Autonomous Agents (LAAs). An LAA is able to generate actions with its core LLM and interact with environments, which facilitates the ability to resolve complex tasks by conditioning on past interactions such as observations and actions. Since the investigation of LAA is still very recent, limited explorations are available. Therefore, we provide a comprehensive comparison of LAA in terms of both agent architectures and LLM backbones. Additionally, we propose a new strategy to orchestrate multiple LAAs such that each labor LAA focuses on one type of action, \textit{i.e.} BOLAA, where a controller manages the communication among multiple agents. We conduct simulations on both decision-making and multi-step reasoning environments, which comprehensively justify the capacity of LAAs. Our performance results provide quantitative suggestions for designing LAA architectures and the optimal choice of LLMs, as well as the compatibility of both.


